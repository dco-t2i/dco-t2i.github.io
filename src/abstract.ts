export const abstract = `In this work, we present Direct Consistency Optimization (DCO), a
novel training objective for low-shot fine-tuning of text-to-image
(T2I) diffusion models, inspired by the constrained policy
optimization of reinforcement **learning**. Unlike a regular fine-tuning,
DCO optimizes the model to be consistent with the pretrained model
while adding minimal information about new concepts, and as such it
mitigates knowledge forgetting and improves the compositional
generation ability of personalized T2I models. In addition, we
emphasize the importance of using a comprehensive and visually
grounded caption for reference training images to further enhance the
image-text alignment of personalized T2I generation. We showcase the
efficacy of our method on a T2I model personalization for subject or
style, or both. We show improved image-text alignment of low-shot
fine-tuned T2I models while retaining the competitive subject fidelity
over baselines. The source code will be released.`;
